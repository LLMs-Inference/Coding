# s1：简单的测试时扩展，让小模型推理性能匹敌 o1

## 概述 📓

测试时扩展是一种很有前途的语言建模新方法，它利用额外的测试时计算来提升模型性能。最近，OpenAI 的 o1 模型展现出这种能力，但并未公开分享其方法与实现细节，这导致了许多复现工作。研究者寻求最简单的方法来实现测试时扩展和强大的推理性能。首先，根据通过消融验证的三个标准：难度、多样性和质量，精心策划了一个由 1,000 个问题组成的小型数据集 s1K，并配以推理轨迹。其次，开发了预算强制功能，通过强制终止模型的思考过程或在模型生成时多次附加 “Wait” 来延长思考过程，从而控制测试时计算。这会导致模型重复检查其答案，往往会修正错误的推理步骤。在对 s1K 上的 Qwen2.5-32B-Instruct 语言模型进行监督微调并为其配备预算强制后，模型 s1-32B 在竞赛数学问题上的表现比 o1-preview 高出 27%（MATH 和 AIME24）。此外，利用预算强制对 s1-32B 进行扩展，还可以在没有测试时干预的情况下推断出更高的性能：在 AIME24 上从 50% 提高到 57%。模型、数据和代码在 https://github.com/simplescaling/s1 上开源。

s1 实际以‌不到 50 美元的云计算成本‌，完成了模型训练，并在数学推理、代码生成等任务中，展现出与 OpenAI 的 o1、DeepSeek 的 R1 等尖端模型相媲美的性能。


## 实现流程 🔍

### 数据来源

从 16 个不同来源收集了 59,029 个问题，其中主要为数学问题。

利用 Google Gemini 2.0 Flash Thinking API 生成推理轨迹，进而获得三元组（问题，推理过程，答案）。为了提高性能，先对 Gemini 进行蒸馏，随后使用 DeepSeek R1 重新生成轨迹。

### 数据处理和生成

1、质量过滤：剔除调用 API 报错的样本后，保留 54,116 个样本；再剔除格式有问题的样本后，保留 51,581 个样本。

2、研究人员筛选出高质量且无需进一步筛选的数据，共 384 个样本，作为最终 1,000 个样本的一部分。

3、难度过滤：Qwen2.5-7B-Instruct 和 Qwen2.5-32B-Instruct 生成问题答案，由 DeepSeek-R1 评估正确性。去除模型回答正确和推理轨迹短的样本后，保留 24,496 个样本。

4、DeepSeek-R1 将数据按数学主题分类（MSC），覆盖 50 个领域。随机选择一个领域后，按照推理链长短排序，优先选择长度较长的样本，并不断迭代，直到得到 1,000 个样本（含之前筛选出的 384 个样本）。

### 微调

使用 1,000 条数据微调 Qwen2.5-32B-Instruct。在 16 块 H100 GPU 上，对 Qwen2.5-32B-Instruct 语言模型进行了 26 分钟的监督微调（平台为 s1K），并为其设定了预算强制。新模型 s1-32B 在竞赛数学问题上的表现，比 o1-preview 高出 27%，具体体现在 MATH 和 AIME24 两个数据集上。

### 测试时扩展

测试时干预：**预算强制**控制模型思考过程，进一步提升模型的性能。具体来说，通过简单追加思考结束（end-of-thinking）token 分隔符和「Final Answer:」，强制设定最大 token 数量。这样，模型能提前退出思考阶段，提供当前最佳答案。为强制设定最小 token 数量，研究抑制思考结束 token 分隔符的生成，并在模型当前推理轨迹后选择性追加「Wait」字符串。此举鼓励模型反思当前生成的内容。
